---
title: "Seahawks Logisitc Regression STNL to BP"
author: "S1"
date: "2025-02-05"
output: html_document
---

Load Dependencies

```{r}
library(readxl)
library(dplyr)
library(caret)
library(corrplot)
```

Load in Data

```{r}
stnl_to_bp <- read.csv("~/calpoly/BusinessAnalytics/GSB503HAWKS/data/mergeData/stnl_to_bp_modelData_Purchases.csv")
```

Prepare for Logistic Regression

```{r}
# Get categorical data
bins = stnl_to_bp[ ,c('X0.200_purchase', 'X200.800_purchase','X800._purchase','no_purchase')]
stnl_to_bp_no_bins <- stnl_to_bp[, !colnames(stnl_to_bp) %in% colnames(bins)]
# Convert target variable to factor
stnl_to_bp$CONVERSION <- as.factor(stnl_to_bp$CONVERSION)
# Select only numeric columns for scaling
numeric_vars <- stnl_to_bp_no_bins[, sapply(stnl_to_bp_no_bins, is.numeric)]
# Scale only numeric variables
scaled_numeric_vars <- scale(numeric_vars)
# Combine the scaled numeric data, binned data, and the categorical target variable
stnl_to_bp_scaled <- data.frame(scaled_numeric_vars,bins, CONVERSION = stnl_to_bp$CONVERSION)
```

Data Partition

```{r}
# Data Partition
set.seed(1)
stnl_to_bp_scaled$CONVERSION = as.factor(stnl_to_bp_scaled$CONVERSION)
myIndex = createDataPartition(stnl_to_bp_scaled$CONVERSION, p = .6, list = FALSE)
trainSet = stnl_to_bp_scaled[myIndex,]
valSet = stnl_to_bp_scaled[-myIndex, ]
# Set 10 folds with cross validation 
myCtrl = trainControl(method = 'cv', number = 10)
```

Model using cross Validation

```{r}
stnl_to_bp_model <- train(CONVERSION ~ ., 
                         data = trainSet, 
                         method = 'glm', 
                         trControl = myCtrl)
summary(stnl_to_bp_model)
```

Calculate Metrics using Cutoff Value

```{r}
# Make predictions on the validation set (using type = "prob" for probability outputs)
predictions <- predict(stnl_to_bp_model, valSet, type = "prob")
# Convert the predicted probabilities to binary class labels (choose a threshold, e.g., 0.5)
predicted_classes <- ifelse(predictions[, 2] > 0.04, 1, 0)
# Generate the confusion matrix
conf_matrix <- confusionMatrix(as.factor(predicted_classes), as.factor(valSet$CONVERSION))
# Print the confusion matrix
print(conf_matrix)
```

Function for finding cutoff values

```{r}
library(pROC)
library(ggplot2)

# Make predictions on the validation set (using type = "prob" for probability outputs)
predictions <- predict(stnl_to_bp_model, valSet, type = "prob")
# Set up a range of thresholds to test (e.g., from 0 to 1)
thresholds <- seq(0, 1, by = 0.01)
# Initialize vectors to store accuracy and specificity at each threshold
accuracies <- c()
specificities <- c()

# Loop through each threshold, calculate accuracy and specificity
for (threshold in thresholds) {
  # Convert probabilities to class predictions based on the threshold
  predicted_classes <- ifelse(predictions[, 2] > threshold, 1, 0)
  # Calculate confusion matrix
  conf_matrix <- confusionMatrix(as.factor(predicted_classes), as.factor(valSet$CONVERSION))
  # Extract accuracy and specificity from the confusion matrix
  accuracies <- c(accuracies, conf_matrix$overall["Accuracy"])
  specificities <- c(specificities, conf_matrix$byClass["Specificity"])
}

# Create a data frame to plot accuracy and specificity vs. threshold
plot_data <- data.frame(Threshold = thresholds, Accuracy = accuracies, Specificity = specificities)
difference <- abs(accuracies - specificities)
closest_threshold_index <- which.min(difference)
closest_threshold <- thresholds[closest_threshold_index]
closest_accuracy <- accuracies[closest_threshold_index]
closest_specificity <- specificities[closest_threshold_index]
# Print the threshold where accuracy and specificity meet
cat("Threshold where accuracy and specificity meet:", closest_threshold, "\n")
cat("Accuracy at this threshold:", closest_accuracy, "\n")
cat("Specificity at this threshold:", closest_specificity, "\n")

# Plot the accuracy and specificity
ggplot(plot_data, aes(x = Threshold)) +
  geom_line(aes(y = Accuracy, color = "Accuracy")) +
  geom_line(aes(y = Specificity, color = "Specificity")) +
  labs(title = "Accuracy and Specificity vs. Threshold",
       x = "Threshold", 
       y = "Metric Value") +
  scale_color_manual(values = c("Accuracy" = "blue", "Specificity" = "red")) +
  theme_minimal()
#----------------------------------------------
```
