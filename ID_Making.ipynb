{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stnl = pd.read_csv('stnl_clean.csv')\n",
    "len(stnl)\n",
    "\n",
    "stnl = stnl.reset_index(drop=True)  # Reset index to ensure correct ordering\n",
    "stnl['Cust_ID'] = range(1, len(stnl) + 1)  # Assign unique ID based on row count\n",
    "\n",
    "stnl = stnl.drop(columns=['ID'], errors='ignore')\n",
    "\n",
    "# Save the cleaned dataset as a CSV\n",
    "stnl.to_csv(\"stnl_ids.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp = pd.read_csv('bp_clean.csv')\n",
    "len(bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the dataset has exactly 1,500 rows\n",
    "if bp.shape[0] == 1500:\n",
    "    # Drop the \"ID\" column if it exists\n",
    "    bp = bp.drop(columns=['ID'], errors='ignore')\n",
    "\n",
    "    # Assign unique Cust_ID values from 12,001 to 13,500\n",
    "    bp['Cust_ID'] = range(12001, 13501)\n",
    "\n",
    "    # Save the updated dataset to a new CSV\n",
    "    bp.to_csv(\"bp_ids.csv\", index=False)\n",
    "\n",
    "    print(bp.head())  # Verify the first few rows\n",
    "else:\n",
    "    print(f\"Dataset has {bp.shape[0]} rows instead of 1,500. Adjust needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_ids = pd.read_csv('bp_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sth = pd.read_csv('sth_clean.csv')\n",
    "len(sth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the dataset has exactly 500 rows\n",
    "if sth.shape[0] == 500:\n",
    "    # Drop the \"ID\" column if it exists\n",
    "    sth = sth.drop(columns=['ID'], errors='ignore')\n",
    "\n",
    "    # Assign unique Cust_ID values from 13,501 to 14,000\n",
    "    sth['Cust_ID'] = range(13501, 14001)\n",
    "\n",
    "    # Save the updated dataset to a new CSV\n",
    "    sth.to_csv(\"sth_ids.csv\", index=False)\n",
    "\n",
    "    print(sth.head())  # Verify the first few rows\n",
    "else:\n",
    "    print(f\"Dataset has {sth.shape[0]} rows instead of 500. Adjust needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sth_ids = pd.read_csv('sth_ids.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lost Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4384"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lost1 = pd.read_csv('lost1_clean.csv')\n",
    "len(lost1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CUSTOMER_KEY  LOB_SEAHAWKS  LOB_FGI  ACTIVITY_CODE_email_click  \\\n",
      "0 -9222442665376300000      0.333333     0.00                   0.666667   \n",
      "1 -9219114118600400000      1.000000     0.00                   0.000000   \n",
      "2 -9218976771547270000      0.600000     0.00                   0.400000   \n",
      "3 -9215066619833900000      0.000000     0.00                   1.000000   \n",
      "4 -9210585509680820000      0.500000     0.25                   0.250000   \n",
      "\n",
      "   ACTIVITY_CODE_email_unsub  ACTIVITY_CODE_form_submission  \\\n",
      "0                        0.0                            0.0   \n",
      "1                        0.0                            0.0   \n",
      "2                        0.0                            0.0   \n",
      "3                        0.0                            0.0   \n",
      "4                        0.0                            0.0   \n",
      "\n",
      "   ACTIVITY_CODE_forward_received  ACTIVITY_CODE_forward_send  \\\n",
      "0                            0.00                         0.0   \n",
      "1                            0.00                         0.0   \n",
      "2                            0.00                         0.0   \n",
      "3                            0.00                         0.0   \n",
      "4                            0.25                         0.0   \n",
      "\n",
      "   ACTIVITY_CODE_merch_purchase  ACTIVITY_CODE_page_view  \\\n",
      "0                           0.0                      0.0   \n",
      "1                           0.0                      0.0   \n",
      "2                           0.0                      0.6   \n",
      "3                           0.0                      0.0   \n",
      "4                           0.0                      0.0   \n",
      "\n",
      "   ACTIVITY_CODE_primary_purchase_club  ACTIVITY_CODE_primary_purchase_ga  \\\n",
      "0                                  0.0                               0.00   \n",
      "1                                  0.0                               0.00   \n",
      "2                                  0.0                               0.00   \n",
      "3                                  0.0                               0.00   \n",
      "4                                  0.0                               0.25   \n",
      "\n",
      "   ACTIVITY_CODE_primary_purchase_single  ACTIVITY_CODE_primary_purchase_sth  \\\n",
      "0                                    0.0                                 0.0   \n",
      "1                                    0.0                                 0.0   \n",
      "2                                    0.0                                 0.0   \n",
      "3                                    0.0                                 0.0   \n",
      "4                                    0.0                                 0.0   \n",
      "\n",
      "   ACTIVITY_CODE_primary_purchase_suite  ACTIVITY_CODE_secondary_purchase  \\\n",
      "0                                   0.0                          0.333333   \n",
      "1                                   0.0                          0.000000   \n",
      "2                                   0.0                          0.000000   \n",
      "3                                   0.0                          0.000000   \n",
      "4                                   0.0                          0.000000   \n",
      "\n",
      "   ACTIVITY_CODE_secondary_sale  ACTIVITY_CODE_survey_submission  \\\n",
      "0                           0.0                              0.0   \n",
      "1                           0.0                              0.0   \n",
      "2                           0.0                              0.0   \n",
      "3                           0.0                              0.0   \n",
      "4                           0.0                              0.0   \n",
      "\n",
      "  CAMPAIGN_LOST  Cust_ID  \n",
      "0    STNL to BP    14001  \n",
      "1    STNL to BP    14002  \n",
      "2     BP to STH    14003  \n",
      "3    STNL to BP    14004  \n",
      "4    STNL to BP    14005  \n"
     ]
    }
   ],
   "source": [
    "# Ensure the dataset has the expected number of rows\n",
    "expected_rows = 18384 - 14001 + 1  # 4384 rows\n",
    "if lost1.shape[0] == expected_rows:\n",
    "    # Assign unique Cust_ID values from 14001 to 18384\n",
    "    lost1['Cust_ID'] = range(14001, 18385)\n",
    "\n",
    "    # Drop the 'ID' column if it exists\n",
    "    if 'ID' in lost1.columns:\n",
    "        lost1 = lost1.drop(columns=['ID'])\n",
    "\n",
    "    # Save the updated dataset to a new CSV\n",
    "    lost1.to_csv(\"lost1_ids.csv\", index=False)\n",
    "\n",
    "    # Verify the first few rows\n",
    "    print(lost1.head())\n",
    "\n",
    "else:\n",
    "    print(f\"Dataset has {lost1.shape[0]} rows instead of {expected_rows}. Adjust needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purchase Data Current List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stnl_purchase = pd.read_csv('cleanDataPurchase/stnl_purchases_clean.csv')\n",
    "len(stnl_purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stnl_purchase = stnl_purchase.reset_index(drop=True)  # Reset index to ensure correct ordering\n",
    "stnl_purchase['Cust_ID'] = range(1, len(stnl_purchase) + 1)  # Assign unique ID based on row count\n",
    "\n",
    "stnl_purchase = stnl_purchase.drop(columns=['ID'], errors='ignore')\n",
    "\n",
    "# Save the cleaned dataset as a CSV\n",
    "stnl_purchase.to_csv(\"stnl_purchase_ids.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_purchase = pd.read_csv('cleanDataPurchase/bp_purchases_clean.csv')\n",
    "len(bp_purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the dataset has exactly 1,500 rows\n",
    "if bp_purchase.shape[0] == 1500:\n",
    "    # Drop the \"ID\" column if it exists\n",
    "    bp_purchase = bp_purchase.drop(columns=['ID'], errors='ignore')\n",
    "\n",
    "    # Assign unique Cust_ID values from 12,001 to 13,500\n",
    "    bp_purchase['Cust_ID'] = range(12001, 13501)\n",
    "\n",
    "    # Save the updated dataset to a new CSV\n",
    "    bp_purchase.to_csv(\"bp_purchase_ids.csv\", index=False)\n",
    "\n",
    "    print(bp_purchase.head())  # Verify the first few rows\n",
    "else:\n",
    "    print(f\"Dataset has {bp_purchase.shape[0]} rows instead of 1,500. Adjust needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sth_purchase = pd.read_csv('cleanDataPurchase/sth_purchases_clean.csv')\n",
    "len(sth_purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ACTIVITY_CODE_primary_purchase_club  ACTIVITY_CODE_primary_purchase_ga  \\\n",
      "0                                  0.0                                0.0   \n",
      "1                                  0.0                                0.0   \n",
      "2                                  0.0                                0.0   \n",
      "3                                  0.0                                0.0   \n",
      "4                                  0.0                                0.0   \n",
      "\n",
      "   ACTIVITY_CODE_primary_purchase_single  ACTIVITY_CODE_primary_purchase_sth  \\\n",
      "0                               0.000000                            0.000741   \n",
      "1                               0.000000                            0.001314   \n",
      "2                               0.001412                            0.001412   \n",
      "3                               0.001553                            0.003106   \n",
      "4                               0.000000                            0.001538   \n",
      "\n",
      "   ACTIVITY_CODE_primary_purchase_suite  ACTIVITY_CODE_secondary_purchase  \\\n",
      "0                                   0.0                          0.000000   \n",
      "1                                   0.0                          0.000000   \n",
      "2                                   0.0                          0.001412   \n",
      "3                                   0.0                          0.000000   \n",
      "4                                   0.0                          0.000000   \n",
      "\n",
      "   ACTIVITY_CODE_secondary_sale  ACTIVITY_CODE_merch_purchase  perc_open  \\\n",
      "0                      0.004817                           0.0   2.645773   \n",
      "1                      0.007884                           0.0   0.314647   \n",
      "2                      0.007062                           0.0   0.266667   \n",
      "3                      0.020186                           0.0   0.393939   \n",
      "4                      0.006154                           0.0   0.092843   \n",
      "\n",
      "   perc_click  Totals  Cust_ID  \n",
      "0    0.082645    2699    13501  \n",
      "1    0.068966     761    13502  \n",
      "2    0.291667     708    13503  \n",
      "3    0.358974     644    13504  \n",
      "4    0.062500     650    13505  \n"
     ]
    }
   ],
   "source": [
    "# Ensure the dataset has exactly 500 rows\n",
    "if sth_purchase.shape[0] == 500:\n",
    "    # Drop the \"ID\" column if it exists\n",
    "    sth_purchase = sth_purchase.drop(columns=['ID'], errors='ignore')\n",
    "\n",
    "    # Assign unique Cust_ID values from 13,501 to 14,000\n",
    "    sth_purchase['Cust_ID'] = range(13501, 14001)\n",
    "\n",
    "    # Save the updated dataset to a new CSV\n",
    "    sth_purchase.to_csv(\"sth_purchase_ids.csv\", index=False)\n",
    "\n",
    "    print(sth_purchase.head())  # Verify the first few rows\n",
    "else:\n",
    "    print(f\"Dataset has {sth_purchase.shape[0]} rows instead of 500. Adjust needed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
